{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentence = \"This apple is sold with the price $3.9.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['This', 'apple', 'is', 'sold', 'with', 'the', 'price', '$', '3.9', '.']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(sentence)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'month', 'of', 'Oct.', 'is', 'the', 'anniversary', 'of', 'ABC', 'Corp', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence2 = \"The month of Oct. is the anniversary of ABC Corp.\"\n",
    "print(word_tokenize(sentence2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'analyst', \"'s\", 'documents', 'does', \"n't\", 'pass', 'the', 'plagiarism', 'check', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence3 = \"The analyst's documents doesn't pass the plagiarism check.\"\n",
    "print(word_tokenize(sentence3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'house', 'loan', 'is', 'worth', '$', '4', 'million']\n",
      "['The', 'house', 'loan', 'is', 'worth', '4', 'million', 'dollars']\n",
      "['The', 'house', 'loan', 'is', 'worth', '$', '4,000,000']\n"
     ]
    }
   ],
   "source": [
    "sentence4 = \"The house loan is worth $4 million\"\n",
    "sentence5 = \"The house loan is worth 4 million dollars\"\n",
    "sentence6 = \"The house loan is worth $4,000,000\"\n",
    "\n",
    "print(word_tokenize(sentence4))\n",
    "print(word_tokenize(sentence5))\n",
    "print(word_tokenize(sentence6))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'normally', 'go', 'to', 'St.', 'Peter', 'church', 'in', 'Melaka', '.']\n",
      "['He', 'live', 'on', '2nd', 'st', 'Avenue', ',', 'New', 'York', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence7 = \"He normally go to St. Peter church in Melaka.\"\n",
    "print(word_tokenize(sentence7))\n",
    "\n",
    "sentence8 = \"He live on 2nd st Avenue, New York.\"\n",
    "print(word_tokenize(sentence8))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Maximum matching algorithm\n",
    "checking the text with available words\n",
    "\n",
    "- use `from nltk.corpus import words`\n",
    "- output in tokens (list)\n",
    "- Python `string.lower()`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "['maximum', 'matching', 'algorithm', 'is', 'cool']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "\n",
    "def maximum_matching(unsegmentedText:str):\n",
    "    all_words = list(words.words())\n",
    "\n",
    "    tokens = []\n",
    "    text = unsegmentedText\n",
    "\n",
    "    boundary = 1\n",
    "\n",
    "    while len(text) != 0:\n",
    "        start_with = text[0:boundary]\n",
    "        possible_words = []\n",
    "        for i in all_words:\n",
    "            if i in text and i[0] == start_with:\n",
    "                possible_words.append(i)\n",
    "        for p in sorted(possible_words, key=len, reverse=True):\n",
    "            if p == text[:len(p)]:\n",
    "                tokens.append(p)\n",
    "                text = text[len(p):]\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "    return tokens\n",
    "\n",
    "maximum_matching('maximummatchingalgorithmiscool')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}