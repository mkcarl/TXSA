{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Question 1\n",
    "Using Data_1.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Demonstrate sentence segmentation and report the output."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is one thing to automatically detect that a particular word occurs in a text, and to\n",
      "display some words that appear in the same context. However, we can also determine\n",
      "the location of a word in the text: how many words from the beginning it appears. This\n",
      "positional information can be displayed using a dispersion plot. Each stripe represents\n",
      "an instance of a word, and each row represents the entire text.\n"
     ]
    }
   ],
   "source": [
    "with open(\"Data_1.txt\", 'r') as f:\n",
    "    data = f.read()\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The data may seem fine at first glance, however, there are special characters like the newline character `\\n` present in the data. We need to remove these characters first."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. Each stripe represents an instance of a word, and each row represents the entire text.\n"
     ]
    }
   ],
   "source": [
    "data = data.replace('\\n', ' ')\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To perform sentence segmentation, we can use the sent_tokenize() function from NLTK"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 sentence(s) in the paragraph.\n",
      "The sentences are : \n",
      "1. It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context.\n",
      "2. However, we can also determine the location of a word in the text: how many words from the beginning it appears.\n",
      "3. This positional information can be displayed using a dispersion plot.\n",
      "4. Each stripe represents an instance of a word, and each row represents the entire text.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "result = sent_tokenize(data)\n",
    "print(f'There are {len(result)} sentence(s) in the paragraph.')\n",
    "print('The sentences are : ')\n",
    "for i, val in enumerate(result):\n",
    "    print(f\"{i+1}. {val}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Demotrate word tokenisation using the split function, Regular Expression and NLTK packages separately and report the output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this, let's use the first sentence from the 4 that was extracted from the paragraph above."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context.'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = result[0]\n",
    "sentence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using Python `split` function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text,', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context.']\n",
      "There are 26 words.\n"
     ]
    }
   ],
   "source": [
    "words_split = sentence.split()\n",
    "print(words_split)\n",
    "print(f'There are {len(words_split)} words.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using RegEx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text,', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context.']\n",
      "There are 26 words.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "words_re = re.split(r'\\s+', sentence) # \\s for any whitespace characters, + for one or more\n",
    "print(words_re)\n",
    "print(f'There are {len(words_re)} words.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using NLTK"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', '.']\n",
      "There are 28 words.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words_nltk = word_tokenize(sentence)\n",
    "print(words_nltk)\n",
    "print(f'There are {len(words_nltk)} words.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context']\n",
      "There are 26 words.\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "blob = TextBlob(sentence)\n",
    "words_blob = blob.words\n",
    "print(words_blob)\n",
    "\n",
    "print(f'There are {len(words_blob)} words.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analysis\n",
    "From the number of items in each list, there seem to be an inconsistent report for NLTK's word tokenization. However, upon closer inspection, NLTK `word_tokenize()` function splits the punctuations (like comma and period) into its own item, while Python `split()` function and RegEx `split()` function groups the punctuation together with the word. However, TextBlob takes it one step further than NLTK as it achieves the same results as NLTK `word_tokenize()`, additionally removed the additional punctuations like the comma (,) and period (.).\n",
    "\n",
    "I think it is better to use TextBlob to do word tokenization as it can properly tokenize the words, and removed any trailing punctuations all in one function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}