{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyO2WCo4fn2jzYkxpc7qYcKv"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# Read data in text file\n",
    "file = open(\"Text Corpus.txt\")\n",
    "data = file.read()\n",
    "print(data)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8CxrTi3r4mD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670931781532,
     "user_tz": -480,
     "elapsed": 5,
     "user": {
      "displayName": "De Long Sia",
      "userId": "15448833127511611982"
     }
    },
    "outputId": "587e1081-6289-4fb9-a740-30416b5ea6fa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<s> He read a book </s>\n",
      "<s> I read a different book </s>\n",
      "<s> He read a book my Danielle </s>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Tokenize every word in the data and clean the data\n",
    "tokens = data.split()\n",
    "\n",
    "cleannedTokens = [token for token in tokens if token != \"<s>\"]\n",
    "cleannedTokens = [token for token in cleannedTokens if token != \"</s>\"]\n",
    "print(cleannedTokens)\n",
    "\n",
    "totalToken = len(cleannedTokens)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAmfr339HPC_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670931373022,
     "user_tz": -480,
     "elapsed": 2,
     "user": {
      "displayName": "De Long Sia",
      "userId": "15448833127511611982"
     }
    },
    "outputId": "bfe04708-c53f-4cd1-d26f-ce8bfc3813c2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['He', 'read', 'a', 'book', 'I', 'read', 'a', 'different', 'book', 'He', 'read', 'a', 'book', 'my', 'Danielle']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Create a list of unique token from the data\n",
    "uniqueTokens = list(set(cleannedTokens))\n",
    "print(uniqueTokens)\n",
    "\n",
    "totalUniqueToken = len(uniqueTokens)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfG8jzgaJgXu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670931408103,
     "user_tz": -480,
     "elapsed": 558,
     "user": {
      "displayName": "De Long Sia",
      "userId": "15448833127511611982"
     }
    },
    "outputId": "40a80df7-504f-442b-9636-b5cf44d4e429",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['my', 'Danielle', 'read', 'different', 'I', 'book', 'He', 'a']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Frequency for each unique token\n",
    "frequencyResult = \"\"\n",
    "\n",
    "for uniqueToken in uniqueTokens:\n",
    "  frequency = cleannedTokens.count(uniqueToken)\n",
    "  frequencyResult = frequencyResult + \"Count(\" + uniqueToken + \") = \" + str(frequency) + \"\\n\""
   ],
   "metadata": {
    "id": "fD1zMqV7QOd4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Unsmoothed Unigram Probabilities\n",
    "unsmoothedResult = \"\"\n",
    "\n",
    "for uniqueToken in uniqueTokens:\n",
    "  probability = cleannedTokens.count(uniqueToken) / totalToken\n",
    "  unsmoothedResult = unsmoothedResult + \"P(\" + uniqueToken + \") = \" + str(probability) + \"\\n\""
   ],
   "metadata": {
    "id": "aRIuh7pRJ4-S",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Smoothed Unigram Probabilities \n",
    "smoothedResult = \"\"\n",
    "\n",
    "for uniqueToken in uniqueTokens:\n",
    "  probability = (cleannedTokens.count(uniqueToken) + 1) / (totalToken + totalUniqueToken + 1)\n",
    "  smoothedResult = smoothedResult + \"P(\" + uniqueToken + \") = \" + str(probability) + \"\\n\""
   ],
   "metadata": {
    "id": "HEZ6UDgTNRu-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Summary of unigram probabilities\n",
    "print(\"Number of Tokens: \" + str(totalToken))\n",
    "print(\"Number of Unique Tokens: \" + str(totalUniqueToken) + \"\\n\")\n",
    "print(\"Frequency of Tokens:\\n\" + frequencyResult)\n",
    "print(\"Unsmoothed Probabilities of Tokens:\\n\" + unsmoothedResult)\n",
    "print(\"Smoothed Probabilities of Tokens:\\n\" + smoothedResult)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kNlUOSN6Oubf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1670931611639,
     "user_tz": -480,
     "elapsed": 416,
     "user": {
      "displayName": "De Long Sia",
      "userId": "15448833127511611982"
     }
    },
    "outputId": "cb95bdfb-894d-4dd7-d8f9-edd85e5a8325",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Tokens: 15\n",
      "Number of Unique Tokens: 8\n",
      "\n",
      "Frequency of Tokens:\n",
      "Count(my) = 1\n",
      "Count(Danielle) = 1\n",
      "Count(read) = 3\n",
      "Count(different) = 1\n",
      "Count(I) = 1\n",
      "Count(book) = 3\n",
      "Count(He) = 2\n",
      "Count(a) = 3\n",
      "\n",
      "Unsmoothed Probabilities of Tokens:\n",
      "P(my) = 0.06666666666666667\n",
      "P(Danielle) = 0.06666666666666667\n",
      "P(read) = 0.2\n",
      "P(different) = 0.06666666666666667\n",
      "P(I) = 0.06666666666666667\n",
      "P(book) = 0.2\n",
      "P(He) = 0.13333333333333333\n",
      "P(a) = 0.2\n",
      "\n",
      "Smoothed Probabilities of Tokens:\n",
      "P(my) = 0.08333333333333333\n",
      "P(Danielle) = 0.08333333333333333\n",
      "P(read) = 0.16666666666666666\n",
      "P(different) = 0.08333333333333333\n",
      "P(I) = 0.08333333333333333\n",
      "P(book) = 0.16666666666666666\n",
      "P(He) = 0.125\n",
      "P(a) = 0.16666666666666666\n",
      "\n"
     ]
    }
   ]
  }
 ]
}